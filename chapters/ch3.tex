\chapter{密度约束下的TopK连续子图匹配问题}
\label{ch3}
本章基于我们提出的新问题——密度约束下的TopK连续子图匹配问题，提出了TopK密度剪枝的基线方法。首先阐述了目前连续子图匹配研究中缺乏与密度有效结合的工作，然后给出了问题的定义以及相关定理的证明，
接着详细描述了CSM-TopK的基础框架以及密度剪枝策略的基线方案，并分析基于密度的剪枝的技术挑战，然后提出本文的核心思想。
\section{引言}
\label{ch3:introduction}
图数据在许多领域中都具有广泛的应用，尤其是在社交网络、交通监控、金融风控等动态变化的场景中，图结构数据的处理和分析变得愈发重要。
图数据的灵活性和复杂性使其成为描述和分析各种关系、网络和交互的理想工具。
在这些应用中，图结构能够有效地反映实体之间的关系，且能够随着时间的推移不断变化，这使得图数据的处理需求变得日益重要。

子图匹配作为图论中的经典问题，已经被广泛研究并应用于多个领域。
其主要任务是从给定的图（数据图）中寻找与查询图（子图）相匹配的子图。
传统的静态图子图匹配方法无法有效处理图的动态变化，因为每次图结构发生变化时，必须重新计算整个匹配过程，这不仅增加了计算开销，也使得实时性要求较高的应用无法得到满足。
因此，如何在动态变化的图中高效地更新和维护子图匹配结果成为了一个重要的研究课题。

为此，提出了连续子图匹配（Continuous Subgraph Matching, CSM）问题，即在动态图中，通过增量更新的方式维护子图匹配结果，避免每次图结构发生变化时重新计算整个匹配过程。
CSM问题的提出使得图数据中的子图匹配变得更加灵活和高效，特别是在处理大规模图数据时，该方法能够显著减少不必要的重复计算，进而提高图数据处理的效率。
尽管连续子图匹配（CSM）问题已得到初步关注，但现有研究主要集中在如何实现匹配结果的增量更新和提高计算效率。
然而，在动态图中，如何根据优先级筛选出最重要的子图匹配结果仍是一个未被充分探讨的问题。
在许多应用场景中，子图匹配结果往往是有优先级的。
例如，在金融欺诈模式检测中，流通金额数更高的匹配的分析优先级可能较高。
由此引出了一个关键问题：如何高效地从众多的匹配结果中筛选出前$k$具有最高密度的子图匹配结果。

基于此，本章提出并研究了一种基线方案，适用于密度约束下TopK续子图匹配问题（CSM-TopK）。
在该方案中，我们首次引入了密度优先级的概念，并通过密度剪枝策略来提高计算效率。
密度优先级是指子图匹配结果的重要性可以通过其密度来量化，密度越高的匹配结果往往具有更高的优先级，因而更值得被保留。
通过密度剪枝，可以在保证匹配结果准确性的同时，减少需要存储的子图匹配数量。
尤其是在动态图中，结合增量更新机制和密度优先级筛选，能够在图数据发生变化时实时获取前$k$个最重要的子图匹配结果。
\section{问题定义和定理证明}
\label{ch3:definition}
\begin{definition}[加权图]
    加权图$G$由顶点集合$V$、边集合$E$、顶点标签函数$L$和边权重函数$W$组成，其中：

    \begin{itemize}
    \item $N_G(v)$表示顶点$v$在$G$中的邻居集合
    \item $L(v)$表示顶点$v$的标签
    \item $W_{v_1, v_2}$表示边$(v_1, v_2)$的权重
    为了明确区分，可以使用$V_G, E_G, L_G, W_G$分别表示图$G$的顶点集、边集、标签函数和权重函数
    \end{itemize}  
    \end{definition}
    
    为简化讨论，本文假设图中的边为无向且无标签，查询边无权重，并使用$v$表示数据顶点，$u$表示查询顶点。
    
    \begin{definition}[动态图]\label{def:dynamic-graph}
    动态图$\iG$由初始图$G_0$和更新流$\Delta$构成，其中：

    \begin{itemize}
    \item 更新流$\Delta$为操作序列$\{o_1, o_2, \cdots\}$
    \item 每个操作$o_t$为三元组$<op, v_1, v_2>$，其中$op$表示操作类型，$op=+$表示边插入操作，$op=-$表示边删除操作
    \item  $G_t$表示在$G_{t-1}$上应用操作$o_t$后形成的图（$t \geq 0$）    
    \end{itemize} 
    \end{definition}
    
    \begin{definition}[子图匹配]\label{def:subgraph-matching}
    子图$g$是查询图$Q$在图$G$中的匹配（子图同构），当且仅当存在双向映射函数$f: V_Q \rightarrow V_g$满足：
    
    \textcircled{1} 顶点标签映射：$\forall u \in V_Q, L_u = L_{f(u)}$；
    
    \textcircled{2} 边映射：$\forall u_1, u_2\in E_Q, (u_1, u_2) \in E_Q \Leftrightarrow (f(u_1), f(u_2)) \in E_g$
    \end{definition}
    
    对图$G_t$ $\in\iG$以及查询图$Q$，用$A_{G_t,Q}$表示所有子图匹配的结果集合。若上下文明确，简写为$A_t$。
    如图~\ref{fig:csm-topk}展示了查询图$Q$（图~\ref{fig:csm-topk}b）在数据图$G$（图~\ref{fig:csm-topk}a）上的多个匹配实例（图~\ref{fig:csm-topk}c）。
    
    \begin{definition}[子图密度]\label{def:subgraph-density}

    对于子图$g$，其密度$den(g)$定义为边权总和：
    \begin{equation}\label{euq:dense_g}
        den(g) = \sum\nolimits_{(v_1,v_2)\in g}\left(W_{v_1,v_2}\right)
    \end{equation}
    
    由于匹配子图的顶点数和边数固定，因此该密度定义等价于图的平均边权定义。
    故子图$g$的密度即为其边的权重之和。
    \end{definition}
    
    \begin{figure}
        \def\wscorevone{0.49\linewidth}
        \centering
        \begin{subfigure}[h!]{0.59\linewidth}
            \centering
            \includegraphics[height=9.5cm]{\figs e_csm_topk_exmaple_d.pdf} % valign=t 顶部对齐
            \caption{数据图$G_t$}
            \label{fig:example_data_graph}
        \end{subfigure}
        \hspace{-0.1cm} % 减小左右子图之间的间距
      % 右侧嵌套竖排子图
      \begin{subfigure}[t]{0.39\linewidth}
        \centering
        \begin{subfigure}[t]{\linewidth} % 右侧上方子图（交通拥堵模式）
          \centering
          \includegraphics[width=\linewidth, height=4cm, keepaspectratio]{\figs e_csm_topk_exmaple_q.pdf} % 固定高度对齐
          \caption{查询图$Q$}
          \label{fig:example_query_graph}
        \end{subfigure}
        \\[2.5em] % 上下间距调整
        \begin{subfigure}[t]{\linewidth} % 右侧上方子图（交通拥堵模式）
            \centering
            \includegraphics[width=\linewidth, height=2.5cm, keepaspectratio]{\figs e_csm_topk_exmaple_r.pdf} % 固定高度对齐
            \caption{结果}
            \label{fig:example_result}
          \end{subfigure}
      \end{subfigure}
      \caption{CSM-TopK应用示例}
      \label{fig:csm-topk}
    \end{figure}
    \begin{definition}[CSM-TopK问题]\label{def:problem-definition}
    给定动态图$\iG=(G_0, \Delta)$、查询图$Q$和参数$k$，对于每个更新操作$o_t\in \Delta$，要求报告当前图$G_t$中满足$Q$匹配条件的前$k$个最密子图集合$A_{t}^k= \{g_1, g_2, \ldots, g_k\}$，其中$A_t^k\subseteq A_t$。
    \end{definition}
    如图\ref{fig:csm-topk}所示，给定$k=3$的一个CSM-TopK案例：
    应用操作$o_t=<+,v_1, v_2>$于$G_{t-1}$，得到$G_t$（图\ref{fig:example_data_graph}），
    查询图$Q$（图\ref{fig:example_query_graph}）由四个查询顶点$\{u_1, u_2, u_3, u_4\}$组成，标签分别为$A,B,C,D$，且按照
    $\{u_1, u_2, u_3, u_4\}$的匹配顺序进行子图匹配。
    最后，从$G_t$中的数千个子图匹配结果中筛选出前$k$个最密子图（$k=3$，图\ref{fig:example_result}），
    $g_0=\{v_1, v_3, v_4, v_9\}$，$g_1=\{v_1, v_3, v_5, v_9\}$，$g_1=\{v_1, v_3, v_6, v_9\}$，密度分别为180，150，140。
    \begin{theorem} \label{theorem:np-hard}
    CSM-TopK属于NP难问题
    \end{theorem}
    \begin{proof}
    通过将图$G$的最大团计算问题~\cite{clique-DBLP:journals/eor/WuH15}归约到CSM-TopK：
    在图$G$上随机生成插入操作，形成一个动态图；
    然后对顶点数从1到$|V_G|$的完全图查询执行CSM-TopK搜索（$k=1$）；
    CSM-TopK返回的最大规模的匹配正是$G$中的最大团。
    该归约过程具有多项式时间复杂度，故CSM-TopK属于NP难问题。
    \end{proof}
\section{CSM-TopK的基线方案}
本节提出了CSM-TopK的基线方案。首先，我们介绍了CSM-TopK的基线框架，后续的所有优化都将在此框架基础上展开；
接着，阐述了如何在该基线框架中引入最坏情况最优连接（worst-case optimal join, 简称 WCOJ）进行扩展部分匹配，并基于第$k$个子图匹配结果作为密度上界，进行简单的剪枝策略。
\subsection{CSM-TopK的基线框架}
\label{ch3:base-framework}
在具有TopK密度约束的连续子图匹配问题上，若要正确且快速的获取top-k子图匹配结果，必须满足以下几个关键条件：

（1）我们需要设计一个高效的密度索引结构，以加速 top-k 子图匹配的搜索过程。
每次的图更新可能引入细微的变化，因此该索引结构需要在动态环境下保持高效性，避免每次更新时重新计算所有匹配。

（2）密度索引结构应在时间和空间成本上都保持轻量，并且易于更新。
为了能够应对不断变化的动态图，索引结构不仅需要支持高效的查询，还要能够快速处理图的增删操作，避免引入过多的计算和存储开销。
我们假设密度索引占用的空间相对较小，且每当图发生更新时，能够高效地维护索引结构。

（3）密度索引结构在查询图匹配过程中起到至关重要的作用。
特别地，当查询图匹配过程中引入密度约束时，密度上限越小，其对匹配过程的约束越强，从而能够有效地剪枝没有希望的中间结果，使得 top-k子图匹配过程更加高效。

在本节中，我们将介绍CSM-TopK的基础框架，第\ref{ch4}章将详细探讨索引结构在该框架中的重要作用，特别是在top-k子图匹配的搜索过程中如何通过剪枝机制显著提升效率。


给定动态图$\iG=(G_0, \Delta)$和查询图$Q$，我们假设$A_0^k$已预先计算完成。对于每个操作$o_t$，我们关注在已获得$A_{t-1}^k$的情况下，如何计算$A_t^k$。
已知图$G_{t-1}$、对应的$A_{t-1}^k$以及操作$o_t=(op, v_1, v_2)$。
若$o_t$为边插入操作（即$op=+$），则只需计算新排序的前$k$个匹配，这些结果可与$A_{t-1}^k$合并得到$A_t^k$。显然，每个新匹配$g$必须包含更新边$(v_1, v_2)$且满足$g\in A_t^k\setminus A_{t-1}^k$。
若$o_t$为边删除操作（即$op=-$），则$A_{t-1}^k$中包含$(v_1, v_2)$的结果将失效。假设删除边$(v_1, v_2)$导致$k^\prime$个结果过期，则需从$G_t$中搜索$k^\prime$个未在$A_{t-1}^k$中出现的高密度匹配进行补充。
每个补充匹配$g^\prime$必须满足$g^\prime \in A_{t-1} \setminus A_{t-1}^k$。

算法\ref{alg:baseline:framework}描述了 CSM-TopK 的基础框架，用于处理动态图中的 top-k 连续子图匹配问题。
输入包括动态图$\iG=(G_0, \Delta)$、查询图$Q$和参数$k$，输出为每个时刻的top-k匹配结果。
算法分为离线预处理和在线处理两个阶段两个部分。

在离线预处理阶段，我们首先为每条查询边 $(u_1, u_2) \in E_Q$ 构建一个匹配序列。初始时，我们选择 $u_1$ 和 $u_2$ 作为起始节点（参见算法 \ref{alg:baseline:framework} 中的第 \ref{code:build-matching-order} 行），
然后使用任何静态子图匹配方法计算 $G_0$ 上查询图$Q$ 的初始top-k匹配集$A_0^k$。
需要注意的是，我们不考虑生成匹配序列的策略，因为匹配序列的生成策略已得到广泛研究。
在本文中，我们采用了一种简单的匹配序列生成方法，首先从第一个查询顶点对（$u_1$，$u_2$）开始，依次选择与已选查询顶点连接最多的下一个顶点。
如果有多个候选查询顶点，我们将从连接数最多的顶点中随机选择一个。

在线处理部分，对于每个更新操作$o_t$，我们首先在 $G_{t-1}$ 上应用 $o_t$更新得到$G_t$，然后将 $A_t^k$ 初始化为 $A_{t-1}^k$，具体的处理步骤如下：
\begin{itemize}
    \item \textbf{边插入操作}（$op=+$）: 如果 $o_t$ 表示插入一条边 $(v_1, v_2)$，该边匹配查询边 $(u_1, u_2)$（见算法 \ref{alg:baseline:framework} 中的第 \ref{code:base-ins:begin} 行至第 \ref{code:base-ins:end} 行），我们会以递归的方式扩展部分匹配 $g^2 = \{v_1, v_2\}$，生成密度较高的完全匹配，匹配顺序从 $u_1$ 和 $u_2$ 开始。
    此递归搜索方法将在 \ref{ch3:wegiht-prune-baseline} 节中进一步讨论（具体见算法 \ref{alg:find-dense-matches} 中的 \emph{FindDenseMatches} 函数）。这种方法保证了在每次插入边后，匹配的更新是增量的，并且通过递归方式尽可能高效地找到新的匹配，并且在递归的过程中舍弃top-k以外的匹配结果。
    \item \textbf{边删除操作}（$op=-$）:  如果 $o_t$ 表示删除一条边 $(v_1, v_2)$（见算法 \ref{alg:baseline:framework} 中的第 \ref{code:base-del:begin} 行至第 \ref{code:base-del:end} 行），
    我们需要删除所有包含 $(v_1, v_2)$ 的过期匹配结果。如果有 $k^\prime$ 个过期的匹配，我们需要在 $G_t$ 中计算另外 $k^\prime$ 个密集匹配以补充答案集合，从而形成新的 $A_{t}^k$。
    为了确保增量更新的正确性，删除操作后的补充匹配策略是非常关键的，必须遍历 $E_{G_t}$ 和 $E_Q$，对于每个匹配关系，其中数据边 $(v_{i_1}, v_{i_2})$ 匹配查询边 $(u_1, u_2)$，我们会对 $g^2 = \{v_{i_1}, v_{i_2}\}$ 进行子图搜索，匹配顺序从 $u_1$ 和 $u_2$ 开始。
    这样可以在删除一条边后，保持top-k匹配的有效性，并通过遍历补充新的密集匹配来维护结果的准确性。
\end{itemize}
\begin{algorithm}[h!]
\small
\caption{\label{alg:baseline:framework}CSM-TopK基础框架}
\KwIn{动态图$\iG=(G_0, \Delta)$，查询$Q$，参数$k$}
\KwOut{各时刻$G_t$的top-k结果$A^k_t$}
	为$Q$的每条边$(u_1, u_2)$构建匹配序列$\Phi$ \label{code:build-matching-order} \\
	在$G_0$上计算初始top-k结果集$A_0^k$ \label{code:build-initial-topk}\\
    \ForEach{$o_t=(op,v_1,v_2)\in \Delta$}{
		应用$o_t$生成新图$G_t$ \\
		初始化$A^k_{t} \leftarrow A^k_{t-1}$ \\
		设$\Phi$为从$u_1,u_2$为起始点的匹配序列\\
        \If{$op = +$}{ \label{code:base-ins:begin}
            \ForEach{$(u_1,u_2)\in E_{Q_t}$\ 匹配\ $(v_1, v_2)$} { 
                设$g^2=\{v_1,v_2\}$, 并将$v_1$,$v_2$设置为已访问\\ \label{code:match-vertex}
				$\mathrm{FindDenseMatches}$($G_t$,$Q$,$\Phi$,$g^2$, $A_t^k$,$k$) \label{code:baseline:end} \\
                /*详细见算法\ref{alg:find-dense-matches}*/  \label{code:base-ins:end}
            }
        }
        \If{$op = -$}{   \label{code:base-del:begin} 
			从当前$A_t^k$中删除所有包含$(v_1, v_2)$的过期匹配 \\
            \If{$(k^\prime = |A_{t-1}^k| - |A_{t}^k|) > 0$}{
                \ForEach{$(v_{i_1},v_{i_2})\in E_{G_{t}}$}{
                        \ForEach{$(u_1,u_2)\in E_{Q}$\ 匹配\ $(v_{i_1},v_{i_2})$}{
                             设$g^2=\{v_{i_1},v_{i_2}\}$并且将$v_{i_1}$, $v_{i_2}$设置为已访问  \\
                             $\mathrm{FindDenseMatches}$($G_t$,$Q$,$\Phi$,$g^2$, $A_t^k$, $k$)\\
                             将$v_{i_1}$、$v_{1i_2}$设置为未访问\label{code:base-del:end} 
                        }
                }
                } 
            } 
       } 
\Return
\end{algorithm}

综合上述，我们可以得出结论，该CSM-TopK框架主要用于增量计算边插入操作后的匹配，并在边删除操作后补充失效的匹配来维持有效的top-k子图匹配的搜索过程。
这种增量更新的方式使得CSM-TopK能够高效地处理动态图中的子图匹配问题，避免了每次操作都重新计算所有可能的匹配，从而显著提升了算法的效率。如果没有引入密度剪枝策略，该问题就转化为“rank after matching”问题。这种情况下，我们必须考虑所有可能的匹配结果，并对其进行排序，最后选出排名前$k$的结果。
这种方法虽然能够解决问题，但在计算上会非常昂贵，尤其是在数据图规模较大，查询图复杂度较高时。没有密度限制的情况下，匹配的空间会急剧扩大，导致计算时间和空间消耗大幅增加。
因此，虽然当前主流的连续子图匹配算法，如Rapidflow\cite{csm-rapidflow-DBLP:journals/pvldb/SunSHL22}, CaLiG\cite{csm-calig-DBLP:journals/pacmmod/YangZZY23}, GraphFlow\cite{csm-graphflow-DBLP:conf/sigmod/KankanamgeSMCS17}等均可应用这一基础框架解决本文的研究问题，但其整体的效率并不高。

%他们将子图的密度定义为其边权之和，即边权总和越大，子图的密度优先级越高。
\subsection{基线方案中的密度剪枝策略}
\label{ch3:wegiht-prune-baseline}
为了高效地计算和维持top-k子图匹配结果，我们在\ref{ch3:base-framework}节中提出的基础框架中引入了密度剪枝策略，从而能够根据密度优先级机制更新匹配结果，并有效减少计算开销。
密度剪枝策略通过计算每个匹配的密度并按优先级进行排序，能够帮助我们迅速丢弃低密度的匹配，减少不必要的计算。
这一策略的引入，使得原本复杂的子图匹配过程变得更加高效，特别是在需要处理大量候选匹配时，能够显著提高算法的执行效率。

密度剪枝策略的核心思想是，首先通过递归搜索来计算部分匹配，并利用最坏情况最优连接（WCOJ）\cite{sm-bfs-DBLP:conf/focs/AtseriasGM08}策略扩展匹配集。随着递归的深入，部分匹配会不断扩展为更大的匹配集，并且我们会根据每个匹配的密度对其进行排序，最终保留前$k$个密度最高的匹配结果，所有第$k$以外的匹配结果都将被剪枝。
这一方案被称为“密度剪枝策略的基线方案”。在算法\ref{alg:find-dense-matches}中，我们详细讨论了利用递归中使用WCOJ以及密度进行剪枝的具体过程，该过程为整个子图匹配的加速提供了重要的支持。

在递归搜索中，我们应用了最坏情况最优连接（WCOJ）\cite{wcoj-generic-join-DBLP:journals/sigmod/NgoRR13}，通过这一策略有效地扩展了部分匹配的候选集（算法 \ref{alg:find-dense-matches}）。
WCOJ是子图匹配领域中一个重要的优化策略，其核心思想是通过交集操作，减少候选匹配集的规模，从而加速整个匹配过程。
WCOJ在多项CSM研究中得到广泛应用\cite{csm-graphflow-DBLP:conf/sigmod/KankanamgeSMCS17,csm-graphflowpp-DBLP:journals/tods/MhedhbiKS21,csm-survey:DBLP:journals/pvldb/SunSLH22}，并且证明了其在大规模图数据中的有效性。

在阐述递归搜索与 WCOJ 的结合之前，我们首先定义查询顶点的左邻居和右邻居，这一概念对于理解WCOJ策略如何在递归过程中有效工作至关重要：
\begin{itemize}
    \item 若 $u_i \in N_Q(u_j)$（即$u_j$和$u_i$之间有边相连） 且 $u_i$ 位于匹配序列 $\Phi$ 中 $u_j$位置的左侧，则称查询顶点 $u_i$ 是 $\Phi$ 中查询顶点$u_j$ 的左邻居。
    对称地, $u_j$ 是 $u_i$ 的右邻居。
    \item $LN_{\Phi}(u_i)$/$RN_{\Phi}(u_i)$ 表示 $\Phi$ 中 $u_i$ 的左/右邻居集合。若上下文清晰，简化为 $LN(u_i)$/$RN(u_i)$。
\end{itemize}   

例如，在图 \ref{fig:csm-topk}b 中，匹配序列为 $\{u_1, u_2, u_3, u_4\}$，则：$LN(u_3) = \{u_1, u_2\}$，表示$u_3$的左邻居是$u_1$和$u_2$。这一结构对于后续的匹配扩展至关重要，因为它决定了如何从当前部分匹配出发，寻找可能的匹配扩展。

定义了左/右邻居之后，我们可以考虑如何在 WCOJ 策略下扩展部分匹配。为了更直观地理解这一过程，假设当前部分匹配 $g^i = \{v_1, v_2, \cdots, v_i\}$，它匹配查询子图 $q^i = \{u_1, u_2, \cdots, u_i\}$，其中 $\Phi = \{u_1, u_2, \cdots, u_{|V(Q)|}\}$，对 $g^i$ 的扩展是计算所有满足 $g^i \subset g^{i+1}$ 且 $g^{i+1}$ 匹配 $q^{i+1}$ 的 $g^{i+1}$ 的集合。
令 $C_{g^{i}}(u_{i+1})$ 表示在 $g^i$ 上 $u_{i+1}$ 的最大可行候选集，其中 $g^i \times C_{g^{i}}(u_{i+1})$ 正是所有满足 $g^i \subset g^{i+1}$ 且 $g^{i+1}$ 匹配 $q^{i+1}$ 的 $g^{i+1}$ 集合。
此外，令 $N_{G_t}^l(v) \subseteq N_{G_t}(v)$ 表示图 $G_t$ 中标签为 $l$ 的顶点 $v$ 的邻居集合。
那么，通过 WCOJ，我们可以通过对已访问的顶点进行交集和过滤来计算 $C_{g^{i}}(u_{i+1})$（算法 \ref{alg:find-dense-matches} 中第 \ref{code:base-intersect:start} 行至第 \ref{code:base-intersect:end} 行）：
\begin{equation} \label{equation:wcoj-intersection}
    %		C_{g^{i}}(u_{i+1}) = \left( \bigcap\limits_{1\leq x^\prime\leq x} \left(  N_{G_t}^{L(u_{i+1})}(v_{i_{x^\prime}}) \right) \right).filterVisited()
    C_{g^{i}}(u_{i+1}) = \bigcap\nolimits_{1\leq x^\prime\leq x} \left(  N_{G_t}^{L(u_{i+1})}(v_{i_{x^\prime}}) \right)  \setminus V_{g^i}
\end{equation}
其中，$v_{i_{x^\prime}}$ 匹配 $u_{i_{x^\prime}}$（$1 \leq x^\prime \leq x$），并且 $\{u_{i_1}, u_{i_2}, \cdots, u_{i_x}\}$ 正是 $\Phi$ 中 $u_{i+1}$ 的左邻居集合。

在图 \ref{fig:csm-topk} 中，以 $o_t = (+,v_1,v_2)$，$\Phi = \{u_1,u_2,u_3,u_4\}$为例，搜索从 $g^2 = \{v_1,v_2\}$ 开始，且已知 $LN(u_3) = \{u_1, u_2\}$。
将部分匹配 $g^2$ 扩展为一系列 $g^3$ 时，我们会计算最大候选集 $C_{g^{2}}(u_3)$，如下所示：
\begin{equation}\label{equation:wcoj-example}
	C_{g^{2}}(u_{3}) =  N_{G_t}^{L(u_{3})}(v_{1})\cap N_{G_t}^{L(u_{3})}(v_{2})  \setminus \{v_1, v_2\}
\end{equation}
因此，$C_{g^{2}}(u_3) = \{v_5, v_6, v_7, v_8\}$，我们可以将 $g^2$ 扩展为 $g^3 = g^2 \cup \{v\}$，其中每个 $v$ 属于 $C_{g^{2}}(u_3)$。

上述是通过WCOJ策略来加速部分匹配的的具体扩展过程。
然而，算法的效率不仅仅依赖于匹配扩展的过程，还受限于如何有效地维护匹配结果及其密度排序。
尽管WCOJ能有效缩小搜索空间，但在大规模图数据中，如何进一步减少不必要的计算仍然是一个挑战。
我们后续将在算法优化部分讨论如何结合密度剪枝策略和拓扑剪枝技术，进一步提升算法的性能。

需要注意的是，本文的重点并不在于加速CSM解法，因此我们没有深入讨论一些基于拓扑的优化策略，如匹配序列选择或拓扑剪枝等内容。
这些策略在CSM的研究中已经有了充分的探讨，且在大多数情况下能够为算法的加速提供有效支持。
相反，我们专注于通过密度剪枝策略来提高top-k子图匹配的效率，尤其是在需要处理大规模图数据时，如何通过密度优先级机制来避免冗余计算和无关匹配的计算开销。



\begin{algorithm}[h!]
	\small
	\caption{密集子图递归搜索过程}
	\label{alg:find-dense-matches}
	\SetKwBlock{iFunc}{Procedure}{End Procedure}
	\iFunc($\mathrm{FindDenseMatches}${(}$G_t, Q, \Phi, g^i, A, k${)})
	{
		\If{$|g^i| = |V_Q| \land g^i\notin A$}{
            设$g_{min}$为$A$中最小密度的匹配\\
			\If{$|A|<k \lor den(g_{min}) < den(g^i)$ }  {  \label{code:g-min-filter}
				将 $g^i$ 加入 $A$集合. \\
				将 $g_{min}$ 从 $A$中移除（if $|A|>k$）
			}
            \Return
		}
		假设 $g^{i}=$\{$v_{1}$, $\cdots$, $v_{i}$\}, $LN(u_{i+1})=$ \{$u_{i_1}$, $\cdots$, $u_{i_x}$\},其中 $v_{i_{x^\prime}}$ 匹配 $u_{i_{x^\prime}}$ ($1\leq x^\prime\leq x$)  \label{code:base-extension:begin} \\
		设$N_{i_{x^\prime}}$ 表示 $N_{G_t}^{L(u_{i+1})}(v_{i_{x^\prime}})$, $1\leq x^\prime\leq x$  \label{code:base-intersect:start} \\
%		// Feasible candidates computation according to WCOJ\\
		$C_{g^i}(u_{i+1})= $ Intersect$(N_{i_1}, \cdots, N_{i_x})$ $\setminus V_{g^i}$  \label{code:intersect}  \label{code:base-intersect:end}\\
		\ForEach{$v \in C_{g^i}(u_{i+1})$}{ \label{code:for-S-begin}
			将$v$设置为已访问，并令$g^{i+1} = g^i\cup \{v\}$ \\
			$\mathrm{FindDenseMatches}${(}$G_t, Q, \Phi, g^{i+1} , A, k${)} \\ 
			将$v$设置为未访问 \label{code:for-S-end}   \label{code:base-extension:end} \\
		}
		\Return 
	}
\end{algorithm}	
\subsection{基线方案的时空复杂度分析}
本文提出的基线方案核心思想是通过增量更新的方式，动态维护前 $k$ 个密度最高的子图匹配结果。由于离线计算阶段不在本文的比较范畴之内，因此本节不对其时空复杂度进行详细分析。

算法\ref{alg:find-dense-matches}的时间复杂度呈指数增长。
由于基线方案采取的是递归扩展策略来生成所有可能的子图匹配路径，并且在递归过程中没有任何的剪枝策略。
因此，其复杂度主要受每个查询节点的候选集合大小影响。设查询图的节点数为$|V_Q|$,初始时已匹配两个节点（见算法\ref{alg:baseline:framework}第\ref{code:match-vertex}行 设置$g_2=\{v_1,v_2\}$），则需递归扩展剩余$k=|V_Q|-2$个节点。
在无剪枝策略的情况下，每次递归需要扩展遍历数据图中所有可能的候选节点。假设数据图$G_t$的平均度为$d_t$，则每一层候选集规模为$O(d_t)$。那么，递归操作的总时间复杂度为
$O(d_{t}^{k})=O(d_{t}^{|V_Q|-2})$。进一步分析，若数据图$G_t$趋近于完全图，其节点数近似为$|V_G|$，则$d_t$可达$O(|V_G|)$,此时算法的时间复杂度将退化为：$O(|V_G|^{|V_Q|-2})$。这一复杂度与子图同构问题的NP难特性一致，表明基线方案在大规模图数据中无法满足实时性的要求。

此外，算法~\ref{alg:baseline:framework} 中的动态更新操作也带来了额外开销。对于插入和删除事件，均需重新调用算法~\ref{alg:find-dense-matches} 以生成新的匹配结果。对于插入操作，最坏情况下存在$|E_Q|$个匹配序列，每条序列都需要独立调用一次算法 \ref{alg:find-dense-matches} 以构建完整的子图匹配。因此，其最坏情况下其时间复杂度为$O(|E_Q||V_G|^{|V_Q|-2})$，平均时间复杂度为$O(|\overline{E_Q}|d_t^{|V_Q|-2})$。对于删除操作，若某个匹配结果过期，需补充$k^{\prime}$个新匹配，此时需扫描整个数据图 $G_t$ 的边集 $|E_{G_t}|$，最坏情况下的时间复杂度为$O(k' |E_{G_t}|  |E_Q|  |V_G|^{|V_Q|-2})$,平均时间复杂度为$O(k' |E_{G_t}|  |\overline{E_Q}| |d_t|^{|V_Q|-2})$。尽管\ref{alg:find-dense-matches}中引入了最坏情况最优连接（Worst-Case Optimal Join）策略，通过候选集交集操作（\ref{equation:wcoj-intersection}）缩小搜索空间，但在最坏情况下（如候选节点邻域极度稀疏或无重叠），交集后的候选集规模仍可能接近原图节点规模 $|V_G|$，导致搜索空间依旧庞大。

基线方案的空间复杂度主要由递归栈的开销以及top-k匹配结果的存储需求共同决定。根据前述分析，递归的最大深度为 $|V_Q| - 2$。在平均情况下，每层递归所需维护的候选节点集大小约为数据图 $G_t$ 的平均度 $d_t$；在最坏情况下，每层候选集大小可达 $|V_G|$。因此，平均空间复杂度为$O(|V_Q|d_t)$,而最坏情况下的递归栈空间开销为$O(|V_Q||V_G|)$。此外，为维持 top-$k$ 个当前密度最高的匹配子图，系统需存储 $k$ 个完整的子图匹配结果。由于每个匹配子图包含 $|V_Q|$ 个节点和$|E_Q|$条边，其空间需求为$O(k|V_Q|+k|E_Q|)$。因此，整个系统的总平均空间复杂度为$O(d_t|V_Q|+k|V_Q|+k|E_Q|)=O(d_t|V_Q|)$。

由此可见，在动态图场景下，基线方案在处理插入操作时效率较低，且删除操作通常需重新计算已失效的匹配结果，从而进一步恶化系统的整体性能。
同时，其空间开销随着数据图规模的增长呈线性上升趋势，若缺乏有效的剪枝机制，极易导致内存资源枯竭。
因此，本方案仅作为本文的基准对比方法，用于评估其他优化策略的有效性和优越性。




\section{技术挑战与核心思想}
本小节主要探讨了CSM-TopK框架中的技术挑战与核心思想。
首先，介绍了CSM-TopK框架中存在的低效问题，特别是在插入和删除操作时的计算浪费，并提出了减少不必要计算的需求。
接着，重点讨论了基于密度的剪枝挑战，提出在处理大规模数据时，如何设计高效的密度上界函数来有效降低计算开销。
为应对这些挑战，我们提出了核心思想：构建压缩图上的全局MWstar和局部MWstar索引结构，  旨在构建紧密的密度上界函数，有效支持基于密度的剪枝策略，
并通过压缩图进一步提升了性能。
\subsection{CSM-TopK 基线框架的效率瓶颈}

在现有的基线方案中，我们直接应用现有的 CSM 搜索策略来计算 CSM-TopK，然而这种方式效率较低。
具体而言，当 $o_t$ 是一个插入操作时，基线方法需要计算所有新增的匹配，即 $A_{t} \setminus A_{t-1}$，然后从 $A_{t-1}^k \cup (A_{t} \setminus A_{t-1})$ 中检索前 $k$ 个密度最高的匹配，从而构建 $A_t^k$。
然而，若某个新增匹配 $g$的密度未能进入前 $k$ 名（即 $g \in A_{t} \setminus A_{t-1}$，但 $g \notin A_{t}^k \setminus A_{t-1}^k$），那么所有关于 $g$ 的计算将变为无效开销。

以图 \ref{fig:csm-topk} 为例，假设 $o_t = <+, v_1, v_2>$，查询顶点匹配序列 $\Phi = \{u_1, u_2, u_3, u_4\}$，搜索过程从 $g^2 = \{v_1, v_2\}$ 开始，其中 $C_{g^{2}}(u_{3}) = \{v_5, v_6, v_7, v_8\}$。
因此，对于每个 $v \in C_{g^{2}}(u_{3})$，我们可以将 $g^2$ 扩展为 $g^3 = g^2 \cup \{v\}$。
与此同时，在将 $g^3$ 扩展为完全匹配（$|V_Q| = 4$）的过程中，我们计算每个 $v \in C_{g^{2}}(u_{3})$ 的候选集 $C_{g^{3}}(u_{4}) = \{v_{1001}, \dots, v_{2000}\}$。
因此，总共计算了 $4000$ 个新增匹配（$|g^2| \times |C_{g^{2}}(u_{3})| \times |C_{g^{3}}(u_{4})|$），但是这些新增匹配的密度都无法进入 $A^k_t$（见图 \ref{fig:csm-topk}c）。
为了提高效率，我们需要尽可能减少对排名在前 $k$ 名之外的匹配进行计算。


这种计算浪费在 $o_t$ 为删除操作时尤为严重。
在这种情况下，我们可能需要计算整个 $A_{t}$，以补充密度较高但已过期的匹配（如果存在）。
因此，减少不必要的计算并提高算法的适应性是 CSM-TopK 框架面临的关键挑战。


\subsection{基于密度的剪枝挑战}

现有的 CSM 方法主要关注基于拓扑的索引设计。但在 CSM-TopK 中，设计基于密度的剪枝策略对于提高效率至关重要。
密度剪枝不仅能减少计算量，还能提高搜索效率，尤其是在处理大规模数据时尤为重要。
一般而言，对于一个部分匹配 $g^i$，我们不仅需要考虑它是否能够扩展为完全匹配，还需要评估这些完全匹配的密度上界。
如果可以确定 $g^i$ 无法形成新的前 $k$ 个结果，则应当立即丢弃该匹配，从而避免不必要的计算开销。

因此，除了拓扑剪枝策略外，我们需要设计一个高效的函数，用于计算每个部分匹配在 $G_t$ 中可能扩展出的完全匹配的密度上界。
如果该密度上界超出了已发现匹配的前 $k$ 名，那么我们可以安全地剪枝 $g^i$，从而减少计算开销。

设计该密度上界函数时主要面临三大挑战：

\begin{itemize}
    \item \textbf{密度上限的紧密性}:密度上界需足够紧密，以确保较强的剪枝能力，能够有效地减少不必要的匹配计算。如果上界过于松散，可能无法提供有效的剪枝效果，导致计算仍然较为低效。
    \item \textbf{密度函数的可维护性}:由于在动态场景中可能会发生频繁的更新操作，因此密度上界函数必须易于维护和更新。特别是在数据图动态变化时，密度函数应能快速调整，而不影响整体性能。
    \item \textbf{计算效率}:密度上界函数需保持轻量级，能够在大规模图数据上高效运行。为避免对每个部分匹配进行复杂计算，我们需设计高效的算法以确保密度计算的快速性。
\end{itemize}   

\subsection{核心思想}
为解决上述挑战，我们提出了两种索引结构：全局 MWstar 和局部 MWstar。这两种索引结构共同为每个部分匹配 $g^i$ 构建了一个紧凑的密度上界函数。
基于 MWstar 的密度上界函数在基于密度的剪枝中表现出显著的效果，且该函数仅需线性空间，能够在近乎常数级的时间内更新。

此外，我们在每个 $G_t$ 之上维护了压缩图，以进一步提升性能。
我们首先在 $G_0$ 上构建压缩图 $\mathcal{G}0$，对于在$G_{t-1}$上应用的每次更新操作$o_t$（$t \geq 1$）形成$G_t$,
在形成更新后的图$G_t$之后，我们将 $\mathcal{G}_{t-1}$ 也相应地转换为 $\mathcal{G}_t$。
压缩图的构建和更新策略确保了其在后续计算中具有较高的效率。
在 $\mathcal{G}_t$ 上运行 CSM-TopK，相较于直接在原始图 $G_t$ 上进行计算，具有更高的效率。
一方面，压缩图上的 MWstar 占用的空间更少，更新时间也更短；
另一方面，压缩图的使用可以减少对无关数据的访问，进一步提升计算效率。
因此在压缩图上结合MWstar索引结构的优化策略，不仅能够提高了密度剪枝的效果，而且在处理大规模数据时表现出了出色的扩展性。
\section{本章小结}
本章系统阐述了基于密度剪枝的连续子图匹配问题（CSM-TopK）的理论基础与基础框架。首先，通过形式化定义动态图、子图匹配、密度度量等核心概念，构建了CSM-TopK问题的数学模型，并基于最大团问题的归约严格证明了该问题的NP难特性。
其次，提出了一种CSM-TopK的基础框架，其核心贡献如下：
\begin{itemize}
\item \textbf{CSM-TopK的基础框架}：构建离线预处理与在线更新相结合的计算框架。离线阶段通过静态子图匹配生成初始top-k结果；在线阶段针对边插入/删除操作，提出了新增匹配扩展与失效匹配补充的策略。

\item \textbf{引入WOCJ机制与密度机制}：在递归搜索过程中引入最坏情况最优连接策略，通过候选集交集运算优化匹配扩展。同时，提出基于第$k$个子图匹配结果构成的密度上界来进行粗略剪枝，减少无效子图匹配结果的存储。

\item \textbf{创新方向提出}：针对上述瓶颈，提出本研究课题的技术挑战与核心思想，指明了提高计算效率的潜在途径。
\end{itemize}    
